{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 3 - Feature Engineering (and Selection)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from geopy import Nominatim\n",
    "import geojson\n",
    "import folium\n",
    "from branca.colormap import LinearColormap, StepColormap\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load and preview the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/sf/data_clean_imputed.csv') # load contents of .csv into a pandas.DataFrame object\n",
    "df.head(5) # display first 5 entries of DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Select the Features we wish to use\n",
    "Feature Selection is normally an iterative process where we set up various experiments to test hypotheses generated during our EDA (e.g. `sqft` appears to have highest correlation and should have greatest impact on our model). We also try different combinations of features and test model accuracy.  \n",
    "For the purpose of this example, we will simply select features which showed good correlation in our EDA."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# keep 'price' for obvious reasons\n",
    "selected_features = ['bath', 'bed', 'property_type', 'sqft', 'postal_code', 'price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Quick Note: Postal code is formatted as an integer so Pandas will not recognize it as a categorical variable. Let's format it as string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.postal_code = df.postal_code.astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df[selected_features]\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Dummy Variables from categorical features\n",
    "In order to exploit the pertinent categorical features for use in our model, we must first convert them to [Dummy Variables]. This essentially creates new columns for each category and encodes a binary 1 or 0 for whether the category is present in that sample.  \n",
    "To do this, we use Pandas built-in function `pandas.get_dummies()`\n",
    "[Dummy Variables]: https://en.wikipedia.org/wiki/Dummy_variable_(statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To get a better understanding of dummy variables, let's get the dummy variables for `property_type`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"before conversion:\")\n",
    "df[['property_type']].head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"after conversion:\")\n",
    "pd.get_dummies(data=df['property_type']).head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We see that the `property_type` column has been replaced by the categories contained within `property_type` with a binary 1 or 0 representing whether that category exists in the sample."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's convert the entire dataframe to dummy variables (Pandas knows to omit numerical variables)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_engineered = pd.get_dummies(data=df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_engineered.head(5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our dataset has now been expanded to include dummy variables!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering  \n",
    "We can further extend our dataset by engineering new features that can have a positive effect on our model.  \n",
    "For example, we have yet to utilize the Lat/Long positions of the houses for any purpose other than visualization. \n",
    "Since location is a major factor in house prices, perhaps we could create a few new features: `average_1km`, `average_2km`, `average_3km` representing the average prices in a 1km, 2km, and 3km radius."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I will leave this as an exercise to the reader to engineer a few features and test if model performance increases."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Save the dataframe to .csv file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_engineered.to_csv('./data/sf/data_clean_engineered.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
