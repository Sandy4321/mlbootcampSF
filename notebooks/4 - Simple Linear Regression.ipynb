{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 4 - Simple Linear Regression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's get our feet wet with a basic Machine Learning algorithm: Simple Linear Regression.  \n",
    "Everyone remembers the equation of a line:  \n",
    "  \n",
    "$$\n",
    "y = mx + b\n",
    "$$ \n",
    "  \n",
    "Given an unknown value of `x`, we can infer `y` by multiplying by slope `m` and adding y-intercept `b`.  \n",
    "Linear Regression uses the same basic concept, however `x` can be multidimensional, denoted as a matrix `X`.  \n",
    "This notebook will deal with only single dimensional `x`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "from sklearn.linear_model import LinearRegression\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn.model_selection import train_test_split\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's load the data and remind ourselves of the contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('./data/rew_van_jan12_clean_engineered.csv')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For this basic linear regression example we will choose only one variable as our independent variable `x`.  \n",
    "In our EDA we discovered that `sqft` was highly correlated with `price` and they also shared a linear relationship.  \n",
    "This makes `sqft` a great candidate for inferring `price` using linear regression.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Recall our line equation: \n",
    "$$\n",
    "y = mx + b\n",
    "$$ \n",
    "\n",
    "We assign the 'price' column of our DataFrame as the dependent variable `y` and the 'sqft' column as the independent variable `x`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x = df['sqft']\n",
    "y = df['price']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Note:  \n",
    "Indexing into a single column of a `pandas.DataFrame` will return a `pandas.Series` object while indexing multiple columns will return another `pandas.DataFrame`. Additionally, the `pandas.Series` object is a wrapper around the popular `numpy.ndarray` datatype. We can get the `numpy.ndarray` from the `Series` using `Series.values`.  \n",
    "See below:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"df type = {}\".format(type(df)))\n",
    "print(\"x type = {}\".format(type(x)))\n",
    "print(\"y type = {}\".format(type(y)))\n",
    "multi_indexed = df[['sqft', 'price']]\n",
    "print(\"multi_indexed type = {}\".format(type(multi_indexed)))\n",
    "ndarray = x.values\n",
    "print(\"x.values type = {}\".format(type(ndarray)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot `price` vs `sqft`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set(rc={'figure.figsize':(12, 8)})# globally set our seaborn plot size to 12 by 8 inches\n",
    "sns.regplot(x, y, fit_reg=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe a linear relationship between `x` and `y` and we could probably visually estimate a best fitting line using our eyes however let's determine this best fitting line algorithmically using [Ordinary Least Squares](https://en.wikipedia.org/wiki/Ordinary_least_squares).  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ordinary Least Squares (OLS) is a great introduction to our first **Optimization** problem in which we are **minimizing** the sum of square differences between the observed and predicted values in order to find the best fit line to the data.  \n",
    "  \n",
    "Basically: \n",
    "1. start with an initial *guess* at the slope `m` and y-intercept `b` of the line equation\n",
    "2. calculate the sum of square differences between the predicted value of `y` and the actual value of `y`.\n",
    "3. adjust parameters (slope `m` and y-intercept `b`) such that error gets *smaller*.\n",
    "4. repeate steps 1-3 until error cannot decrease any further.\n",
    "  \n",
    "See [here] for a quick, interactive tutorial if you're keen on learning more about OLS.\n",
    "[here]: http://setosa.io/ev/ordinary-least-squares-regression/"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Rather than write our linear regressor from scratch, let's use the [LinearRegression] module from [Scikit-Learn], a popular machine learning library.  \n",
    "[LinearRegression]: http://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html\n",
    "[Scikit-Learn]: http://scikit-learn.org/stable/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "regressor = LinearRegression(normalize=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can now simply call `fit()` on the `regressor` object to run OLS to iteratively fit to the training data.  \n",
    "  \n",
    "Note:  \n",
    "`fit()` expects `x` to be a `numpy.ndarray` of shape `(num_samples, num_features)` and `y` to be of shape `(num_samples, 1)`.  \n",
    "Recall we are only dealing with single variable linear regression in this notebook so our number of features is 1 however in multiple linear regression the number of features can be very large. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try first with our `x` and `y` DataFrames so we can get acquianted with the error message in case we encounter something similar in the future"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(\"x.shape = {}\".format(x.shape))\n",
    "print(\"y.shape = {}\".format(y.shape))\n",
    "model = regressor.fit(x,y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We get:  \n",
    "`ValueError: Expected 2D array, got 1D array instead`  \n",
    "Let's reshape our data to 2D `numpy.ndarray`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_samples = len(x)\n",
    "assert len(x) == len(y) # be sure we have the same number of training samples as target samples\n",
    "num_features = 1 # only a single feature, sqft\n",
    "x_np = x.values.reshape((num_samples, num_features))\n",
    "y_np = y.values.reshape((num_samples, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x_np.shape = {}\".format(x_np.shape))\n",
    "print(\"y_np.shape = {}\".format(y_np.shape))\n",
    "model = regressor.fit(x_np, y_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The regressor has been fit to our training data and saved into a variable named `model`.  \n",
    "Now we can call `predict()` to predict `price` for a given `sqft`. For illustrative purposes we will predict on the same data we trained on"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can evaluate the performance of a given model using Scikit-Learn `mean_square_error` and `LinearRegression.score()` function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_model(model, X, y):\n",
    "    y_pred = model.predict(X) # predict y values from input X\n",
    "    mse = mean_squared_error(y_true=y, y_pred=y_pred)\n",
    "    print(\"Mean Squared Error: {}\".format(mse))\n",
    "    print(\"Accuracy: {}%\".format(model.score(X, y)*100.0))\n",
    "evaluate_model(model, x_np, y_np)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As our model improves we expect the MSE to decrease and Accuracy to increase."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's try on a brand new input from https://www.rew.ca/properties/areas/vancouver-bc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# try brand new data\n",
    "actual_price = '$5,688,000'\n",
    "sqft = 3790\n",
    "new_df = pd.DataFrame(data=[sqft])\n",
    "predicted_price = model.predict(new_df)\n",
    "print(\"predicted price: ${}M\".format(predicted_price[0][0]/1e6))\n",
    "print(\"actual price: {}\".format(actual_price))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the predicted values (red) and actual values (blue) on the same graph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "y_pred = model.predict(x_np) # predict y values from input X\n",
    "sns.regplot(x_np, y_np, fit_reg=False, color='red')\n",
    "sns.regplot(x_np, y_pred, fit_reg=False, color='blue')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our model looks like it has fit nicely to the data!  \n",
    "One immediate drawback you may notice is that the predictions are constrained to the regression line which results in a large error for many inputs.  \n",
    "Even more importantly: we have many more features other than `sqft` which can help predict `price`.\n",
    "We address these problems in the next notebook by introducing **multiple linear regression**."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Validation\n",
    "In the above example we trained and tested our model with the same dataset. In practice this is a **big** mistake. We will get false confidence in our model's performance since we didn't validate the it's ability to generalize to new, unseen data from outside of the training set.  \n",
    "This inability to generalize is called [overfitting] and is one of the most common problems Machine Learning Engineers face.  \n",
    "  \n",
    "New data is typically hard to come by but we can do our best to avoid overfitting by \"holding out\" some of our training data as *validation* data. Hopefully our dataset is diverse enough that random sampling a validation dataset can properly represent new, unseen test data.\n",
    "[overfitting]: https://en.wikipedia.org/wiki/Overfitting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use Scikit-Learn's `train_test_split()` to divide our dataset into *training* and *validation* data.  \n",
    "A good rule of thumb is 70% training, 30% validation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_val, y_train, y_val = train_test_split(x_np, \n",
    "                                                  y_np, \n",
    "                                                  test_size=0.30, \n",
    "                                                  random_state=123) # split 70% train, 30% validation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fit the model to our training set and evaluate using our validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= regressor.fit(x_train, y_train)\n",
    "evaluate_model(model, x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The results are very similar to before, however don't expect to get this lucky in practice!  \n",
    "Let's save our model using Python's built-in persistence library `pickle`. That way we can compare results with more complex models in a future notebook."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Since we are reasonably confident our model is not overfitting, let's retrain on the entire dataset before saving"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model= regressor.fit(x_np, y_np)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pickle\n",
    "with open('./models/simple_linear.pkl', 'wb') as f:\n",
    "    pickle.dump(model, f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can reload the model with:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./models/simple_linear.pkl', 'rb') as f:\n",
    "    model_load = pickle.load(f)\n",
    "evaluate_model(model_load, x_val, y_val)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We are done with Linear Regression. Let's see if we can improve our model accuracy by including more features!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
