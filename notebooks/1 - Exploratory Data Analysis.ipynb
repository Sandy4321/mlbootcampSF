{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Part 1 - Exploratory Data Analysis (EDA)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will start with an Exploratory Data Analysis (EDA) of the Vancouver housing dataset.  \n",
    "It is always a good idea to start with an EDA before designing and training a machine learning algorithm.  \n",
    "EDA gives us better insight to the data by using statistical and visualization techniques.  \n",
    "\n",
    "Upon completing this notebook, we should have:  \n",
    "* Familiarity with [Pandas] and [NumPy] for data management and analysis\n",
    "* Familiarity with [Matplotlib] and [seaborn] for visualization\n",
    "* A decent understanding of the characteristics of our dataset\n",
    "[Pandas]: https://pandas.pydata.org/\n",
    "[NumPy]: http://www.numpy.org/\n",
    "[Matplotlib]: https://matplotlib.org/\n",
    "[seaborn]: https://seaborn.pydata.org/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "from scipy import stats\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from geopy import Nominatim\n",
    "import geojson\n",
    "import folium\n",
    "from branca.colormap import LinearColormap, StepColormap\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Let's start by loading the data and have a peek at the contents"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>price</th>\n",
       "      <th>facts and features</th>\n",
       "      <th>real estate provider</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Condo For Sale</td>\n",
       "      <td>550 Davis St UNIT 44</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>94111</td>\n",
       "      <td>$1,995,000</td>\n",
       "      <td>3 bds , 2 ba , 1,520 sqft</td>\n",
       "      <td>Sotheby's International Realty</td>\n",
       "      <td>https://www.zillow.com/homedetails/550-Davis-S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Condo For Sale</td>\n",
       "      <td>240 Lombard St APT 437</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>94111</td>\n",
       "      <td>$625,000</td>\n",
       "      <td>1 bd , 1 ba , 566 sqft</td>\n",
       "      <td>SimpleListing.com</td>\n",
       "      <td>https://www.zillow.com/homedetails/240-Lombard...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Condo For Sale</td>\n",
       "      <td>550 Davis St UNIT 39</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>94111</td>\n",
       "      <td>$1,196,000</td>\n",
       "      <td>1 bd , 1 ba , 914 sqft</td>\n",
       "      <td>NaN</td>\n",
       "      <td>https://www.zillow.com/homedetails/550-Davis-S...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Condo For Sale</td>\n",
       "      <td>77 Dow Pl APT 701</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>94107</td>\n",
       "      <td>$935,000</td>\n",
       "      <td>1 bd , 1.5 ba , 1,022 sqft</td>\n",
       "      <td>Vanguard Properties</td>\n",
       "      <td>https://www.zillow.com/homedetails/77-Dow-Pl-A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>House For Sale</td>\n",
       "      <td>807 Francisco St</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>94109</td>\n",
       "      <td>$16,900,000</td>\n",
       "      <td>6 bds , 6.5 ba , 6,180 sqft</td>\n",
       "      <td>Compass</td>\n",
       "      <td>https://www.zillow.com/homedetails/807-Francis...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            title                 address           city state postal_code  \\\n",
       "0  Condo For Sale    550 Davis St UNIT 44  San Francisco    CA       94111   \n",
       "1  Condo For Sale  240 Lombard St APT 437  San Francisco    CA       94111   \n",
       "2  Condo For Sale    550 Davis St UNIT 39  San Francisco    CA       94111   \n",
       "3  Condo For Sale       77 Dow Pl APT 701  San Francisco    CA       94107   \n",
       "4  House For Sale        807 Francisco St  San Francisco    CA       94109   \n",
       "\n",
       "         price           facts and features            real estate provider  \\\n",
       "0   $1,995,000    3 bds , 2 ba , 1,520 sqft  Sotheby's International Realty   \n",
       "1     $625,000       1 bd , 1 ba , 566 sqft               SimpleListing.com   \n",
       "2   $1,196,000       1 bd , 1 ba , 914 sqft                             NaN   \n",
       "3     $935,000   1 bd , 1.5 ba , 1,022 sqft             Vanguard Properties   \n",
       "4  $16,900,000  6 bds , 6.5 ba , 6,180 sqft                         Compass   \n",
       "\n",
       "                                                 url  \n",
       "0  https://www.zillow.com/homedetails/550-Davis-S...  \n",
       "1  https://www.zillow.com/homedetails/240-Lombard...  \n",
       "2  https://www.zillow.com/homedetails/550-Davis-S...  \n",
       "3  https://www.zillow.com/homedetails/77-Dow-Pl-A...  \n",
       "4  https://www.zillow.com/homedetails/807-Francis...  "
      ]
     },
     "execution_count": 421,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import glob\n",
    "all_csvs = []\n",
    "# load the csv files from all scraping runs\n",
    "for filename in glob.glob('./data/sf/**/*.csv'):\n",
    "    all_csvs.append(pd.read_csv(filename))\n",
    "# combine all dataframes together and drop any duplicate entries\n",
    "df = pd.concat(all_csvs, ignore_index=True).drop_duplicates()\n",
    "# save this combined dataframe as csv for safe keeping\n",
    "df.to_csv('./data/sf/all.csv')\n",
    "# display first 5 entries of DataFrame\n",
    "df.head(5) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Our data is now contained in a variable named `df` which is a pandas DataFrame."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display some quick stats about the DataFrame\n",
    "DataFrame has a few built in functions we can call to get a quick summary of the data:  \n",
    "* `info()` displays a count of all non-null objects and their datatypes  \n",
    "* `describe()` calculates basic statistics about all numerical values in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 538 entries, 0 to 839\n",
      "Data columns (total 9 columns):\n",
      "title                   538 non-null object\n",
      "address                 538 non-null object\n",
      "city                    538 non-null object\n",
      "state                   538 non-null object\n",
      "postal_code             538 non-null object\n",
      "price                   537 non-null object\n",
      "facts and features      538 non-null object\n",
      "real estate provider    417 non-null object\n",
      "url                     538 non-null object\n",
      "dtypes: object(9)\n",
      "memory usage: 42.0+ KB\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>address</th>\n",
       "      <th>city</th>\n",
       "      <th>state</th>\n",
       "      <th>postal_code</th>\n",
       "      <th>price</th>\n",
       "      <th>facts and features</th>\n",
       "      <th>real estate provider</th>\n",
       "      <th>url</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>538</td>\n",
       "      <td>538</td>\n",
       "      <td>538</td>\n",
       "      <td>538</td>\n",
       "      <td>538</td>\n",
       "      <td>537</td>\n",
       "      <td>538</td>\n",
       "      <td>417</td>\n",
       "      <td>538</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>11</td>\n",
       "      <td>521</td>\n",
       "      <td>6</td>\n",
       "      <td>1</td>\n",
       "      <td>27</td>\n",
       "      <td>314</td>\n",
       "      <td>478</td>\n",
       "      <td>110</td>\n",
       "      <td>522</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Condo For Sale</td>\n",
       "      <td>2764 Greenwich St</td>\n",
       "      <td>San Francisco</td>\n",
       "      <td>CA</td>\n",
       "      <td>94109</td>\n",
       "      <td>$1,995,000</td>\n",
       "      <td>1 bd , 1 ba , -- sqft</td>\n",
       "      <td>Zephyr Real Estate</td>\n",
       "      <td>https://www.zillow.com/homedetails/352-Cumberl...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>211</td>\n",
       "      <td>2</td>\n",
       "      <td>494</td>\n",
       "      <td>538</td>\n",
       "      <td>40</td>\n",
       "      <td>13</td>\n",
       "      <td>7</td>\n",
       "      <td>42</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 title            address           city state  postal_code  \\\n",
       "count              538                538            538   538          538   \n",
       "unique              11                521              6     1           27   \n",
       "top     Condo For Sale  2764 Greenwich St  San Francisco    CA        94109   \n",
       "freq               211                  2            494   538           40   \n",
       "\n",
       "             price     facts and features real estate provider  \\\n",
       "count          537                    538                  417   \n",
       "unique         314                    478                  110   \n",
       "top     $1,995,000  1 bd , 1 ba , -- sqft   Zephyr Real Estate   \n",
       "freq            13                      7                   42   \n",
       "\n",
       "                                                      url  \n",
       "count                                                 538  \n",
       "unique                                                522  \n",
       "top     https://www.zillow.com/homedetails/352-Cumberl...  \n",
       "freq                                                    2  "
      ]
     },
     "execution_count": 422,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.info()\n",
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reformat price column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "could not convert string to float: \n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def format_price(price):\n",
    "    \"\"\"Remove all non-numerical and period\"\"\"\n",
    "    price = str(price)\n",
    "    non_decimal = re.compile(r'[^\\d.]+')\n",
    "    price = price.replace('.','')\n",
    "    price = price.replace('K','000')\n",
    "    price = price.replace('M','000000')\n",
    "    price_num = None\n",
    "    try:\n",
    "        price_num = float(non_decimal.sub('', price))\n",
    "    except Exception as e:\n",
    "        print(e)\n",
    "    finally:\n",
    "        return price_num\n",
    "df['price'] = df.price.apply(format_price)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse `facts and features` column into multiple columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-- bds  could not convert string to float: \n",
      "-- bds  could not convert string to float: \n",
      "-- bds  could not convert string to float: \n",
      "-- bds  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- ba  could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft lot could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n",
      "-- sqft could not convert string to float: \n"
     ]
    }
   ],
   "source": [
    "# TODO: consider studio as 0 beds?\n",
    "non_decimal = re.compile(r'[^\\d.]+')\n",
    "def parse_beds(string):\n",
    "    strings = string.lower().split(', ')\n",
    "    num_beds = None\n",
    "    for s in strings:\n",
    "        if \"bd\" in s:\n",
    "            try:\n",
    "                num_beds = float(non_decimal.sub('', s))\n",
    "            except Exception as e:\n",
    "                print(s, e)\n",
    "            finally:\n",
    "#                 print(f'num_beds = {num_beds}')\n",
    "                return num_beds\n",
    "\n",
    "def parse_bath(string):\n",
    "    strings = string.lower().split(', ')\n",
    "    num_bath = None\n",
    "    for s in strings:\n",
    "        if \"ba\" in s:\n",
    "            try:\n",
    "                num_bath = float(non_decimal.sub('', s))\n",
    "            except Exception as e:\n",
    "                print(s, e)\n",
    "            finally:\n",
    "#                 print(f'num_bath = {num_bath}')\n",
    "                return num_bath\n",
    "def parse_sqft(string):\n",
    "    strings = string.lower().split(', ')\n",
    "    sqft = None\n",
    "    for s in strings:\n",
    "        if \"ft\" in s:\n",
    "            try:\n",
    "                sqft = float(non_decimal.sub('', s))\n",
    "            except Exception as e:\n",
    "                print(s, e)\n",
    "            finally:\n",
    "#                 print(f'sqft = {sqft}')\n",
    "                return sqft\n",
    "df['bed'] = df['facts and features'].apply(parse_beds)\n",
    "df['bath'] = df['facts and features'].apply(parse_bath)\n",
    "df['sqft'] = df['facts and features'].apply(parse_sqft)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Parse `title` column into `property_type`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First let's see if there is a pattern to the titles:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Condo For Sale' 'House For Sale' 'Apartment For Sale' 'New Construction'\n",
      " 'Foreclosure' 'Lot/Land For Sale' 'Coming Soon' 'Co-op For Sale'\n",
      " 'Auction' 'For Sale by Owner' 'Townhouse For Sale']\n",
      "Condo For Sale        211\n",
      "House For Sale        150\n",
      "Apartment For Sale    100\n",
      "New Construction       37\n",
      "Coming Soon            12\n",
      "Lot/Land For Sale       9\n",
      "For Sale by Owner       6\n",
      "Auction                 6\n",
      "Co-op For Sale          5\n",
      "Foreclosure             1\n",
      "Townhouse For Sale      1\n",
      "Name: title, dtype: int64\n"
     ]
    }
   ],
   "source": [
    "print(df.title.unique())\n",
    "print(df.title.value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like there is a limited amount of unique values, which is good. We can design our parser to catch most cases."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 417,
   "metadata": {},
   "outputs": [],
   "source": [
    "# map property types\n",
    "property_types = {'Condo For Sale': 'condo', \n",
    "                  'House For Sale': 'house', \n",
    "                  'Apartment For Sale': 'apartment', \n",
    "                  'New Construction': 'new',\n",
    "                  'Foreclosure': 'foreclosure', \n",
    "                   'Lot/Land For Sale': 'lot', \n",
    "                  'Coming Soon': 'coming', \n",
    "                  'Co-op For Sale': 'coop',\n",
    "                  'Auction': 'auction', \n",
    "                  'For Sale by Owner': None, \n",
    "                  'Townhouse For Sale': 'townhouse'}\n",
    "def parse_property_type(string):\n",
    "    try:\n",
    "        property_type = property_types[string]\n",
    "    except KeyError as e:\n",
    "        print(e)\n",
    "        property_type = None\n",
    "    finally:\n",
    "        return property_type\n",
    "df['property_type'] = df['title'].apply(parse_property_type)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "condo          211\n",
       "house          150\n",
       "apartment      100\n",
       "new             37\n",
       "coming          12\n",
       "lot              9\n",
       "auction          6\n",
       "coop             5\n",
       "townhouse        1\n",
       "foreclosure      1\n",
       "Name: property_type, dtype: int64"
      ]
     },
     "execution_count": 418,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.property_type.value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Display some quick stats about the DataFrame\n",
    "DataFrame has a few built in functions we can call to get a quick summary of the data:  \n",
    "* `info()` displays a count of all non-null objects and their datatypes  \n",
    "* `describe()` calculates basic statistics about all numerical values in the DataFrame"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wow, very large maximum price albeit not suprising. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# describe only the 'price' column\n",
    "df['price'].describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## We have the gist of the dataset size and its contents, it's time to go more in depth and Visualize the data.  \n",
    "We will use `Seaborn` to visualize the data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Find a place to show violin plots\n",
    "# TODO: consider PCA for visualizing high dimensional data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot histogram of prices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globally set our seaborn plot size to 12 by 8 inches:\n",
    "sns.set(rc={'figure.figsize':(12, 8)})\n",
    "\n",
    "def plot_prices(df: pd.DataFrame, bins: list):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xticks(bins)\n",
    "    plt.xticks(rotation='vertical')\n",
    "    return sns.distplot(df.price, bins=bins)\n",
    "\n",
    "bins = range(int(df.price.min()), int(df.price.max()), 500000)\n",
    "plot_prices(df.dropna(), bins)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Definitely a skewed distribution, looks as if we have a few outliers at the higher range of the prices.  \n",
    "### We can quantify this by calculating:  \n",
    "* `Skewness` - A measure of the symmetry (or lack thereof) of a distribution\n",
    "* `Kurtosis` - Whether distrubition is \"heavy-tailed\" or \"light-tailed\" or in other words: how \"sharp\" the peak is."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#skewness and kurtosis\n",
    "print(\"Skewness: %f\" % df['price'].skew())\n",
    "print(\"Kurtosis: %f\" % df['price'].kurt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot with outliers removed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_outliers = df[df.price < 15e6]\n",
    "bins = range(int(df_no_outliers.price.min()),int(df_no_outliers.price.max()),500000)\n",
    "plot_prices(df_no_outliers, bins)\n",
    "print(\"Skewness (outliers removed): %f\" % df_no_outliers['price'].skew())\n",
    "print(\"Kurtosis (outliers removed): %f\" % df_no_outliers['price'].kurt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Removing the outliers improved our skewness and kurtosis values.\n",
    "We will remember this when cleaning the data for our model. Machine learning models work best with normally distributed data. Outliers may affect model performance."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Plot missing values.\n",
    "Recall that there were some columns which are incomplete. Plot a bar graph describing this:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = df.isnull().sum()\n",
    "missing = missing[missing > 0]\n",
    "missing.sort_values(inplace=True)\n",
    "missing.plot.bar()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Variables that are missing values can either be removed from the dataset or have their missing values replaced (perhaps with 0 or the mean of the column). Remember this for data cleaning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Since we have geolocations of the houses in the `latlng` column, let's visualize the data on a slippy map and see if there are any patterns w.r.t. price.  \n",
    "We use `folium` to render html in the notebook.  \n",
    "Note that there are hundreds of houses to be displayed and this requires a lot of RAM. If your browser crashes you can adjust the amount to be displayed by changing the variable `display_max`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm_notebook\n",
    "from geopy.geocoders import Nominatim\n",
    "def generate_latlng(dataframe: pd.DataFrame):\n",
    "    dataframe = dataframe.copy()\n",
    "    geocoder = Nominatim()\n",
    "    latlngs = []\n",
    "    for address, city in zip(tqdm_notebook(dataframe.address), dataframe.city):\n",
    "        location = geocoder.geocode(f'{address} {city}')\n",
    "        if location:\n",
    "            latlngs.append((location.latitude, location.longitude))\n",
    "        else:\n",
    "            latlngs.append(None)\n",
    "    dataframe['latlng'] = latlngs\n",
    "    return dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from multiprocessing import Pool\n",
    "job = Pool().apply_async(func=generate_latlng, args=(df,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = job.get()\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def draw_houses_on_map(dataframe: pd.DataFrame):\n",
    "    dataframe = dataframe.copy()\n",
    "    # create a folium map object centered in SF\n",
    "    m = folium.Map(location=(37.7, -122.4))\n",
    "    # create a colormap of the prices (we limit prices between 5e5 and 10e6)\n",
    "    colors = ['gray', 'green','blue','red','orange', 'yellow']\n",
    "    min_price, max_price = 5e5, 6e6\n",
    "    colormap = StepColormap(colors=colors,vmin=min_price, vmax=max_price, caption='price')\n",
    "    m.add_child(colormap)\n",
    "    # amount of points to render on the map. WARNING: significant RAM required to plot all points and may crash your browser \n",
    "    display_max = len(dataframe) # plot all\n",
    "    # display_max = 100 # uncomment and adjust this number if needed\n",
    "    displayed = 0\n",
    "    for i, latlng in zip(dataframe.index, dataframe['latlng']):\n",
    "        price = dataframe.loc[i, 'price']\n",
    "        if latlng is not None and latlng != 'MISSING':\n",
    "            if isinstance(latlng, str):\n",
    "                lat, lng = latlng.replace('(','').replace(')','').split(',')\n",
    "                latlng = (float(lat), float(lng))\n",
    "            if not isinstance(latlng, tuple):\n",
    "                continue\n",
    "            style = {'fillColor': colormap(price),\n",
    "                    'color' : colormap(price)}\n",
    "            p = geojson.Point(coordinates=(latlng[1], latlng[0]), style=style)\n",
    "            # build an HTML string to be displayed if we click a marker.\n",
    "            html_info = '<li>Price: ${}</li><li>Property Type: {}</li>'.format(dataframe.loc[i, 'price'], dataframe.loc[i, 'property_type'])\n",
    "            m.add_child(folium.Marker(location=latlng, icon=folium.Icon(color='black', icon_color=colormap(price)), popup=folium.Popup(html=html_info)))\n",
    "            displayed += 1\n",
    "            if displayed > display_max:\n",
    "                break\n",
    "    return m\n",
    "draw_houses_on_map(df)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### We can observe some patterns w.r.t. location.  \n",
    "### Seems the more expensive homes are Central and North and the \"lower\" (finger quotes) priced homes on the outside"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Next, let's see how some of the variables interact with the list price.  \n",
    "Since `price` is our target variable (the variable we are trying to predict), it is useful visualize how each variable relates to `price`. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### sqft\n",
    "Total square footage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# sqft/saleprice\n",
    "var = 'sqft'\n",
    "sns.regplot(df[var], df['price'], )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The relationship looks linear with some spreading as sqft increases. We can also see there are some houses with almost zero square feet! Let's investigate why:  \n",
    "  \n",
    "Note on `pandas.DataFrame` indexing:  \n",
    "* `df['sqft'] == 0` gives us a \"truth array\" where True values match the condition and False otherwise. If we index the original DataFrame with this truth array we get a filtered result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# filter the DataFrame with nearly zero sqft\n",
    "df[df['sqft'] < 10].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Looks like we have some bad data from the web scraping. We will remember to remove these when we get to our data cleaning notebook"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bed\n",
    "Number of bedrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "var = 'bed'\n",
    "sns.regplot(df[var], df['price'], )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We observe a bit of linearity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### bath\n",
    "Number of bathrooms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "var = 'bath'\n",
    "sns.regplot(df[var], df['price'], )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Relationship appears to be linear."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Generate a correlation matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A correlation matrix will graphically show us which variables are most correlated to our target variable `price`"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TODO: a good explanation of heatmaps here: https://www.kaggleusercontent.com/kf/2154073/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..KfxeCxv48WLAORmGT131Aw.QwZwhYcY6QENL0zU-rCwVvcyXITzFfs1X-Mum5zodrGahfZ9NSDfaSzF7kbocoMmO0fi8m72nware9xs4bOiUrxe9LH6X4Q0qzoYo8TBY0e0He52L0ORo7BOewfCoVLW.D8GjFZ-DLUlizQZOXlbw-g/__results__.html#Interpreting-The-Heatmap"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "corrmat = df.corr()\n",
    "sns.heatmap(corrmat, vmax=1, square=True);"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TODO: Also explain ordinal variables like here: https://www.kaggleusercontent.com/kf/2154073/eyJhbGciOiJkaXIiLCJlbmMiOiJBMTI4Q0JDLUhTMjU2In0..KfxeCxv48WLAORmGT131Aw.QwZwhYcY6QENL0zU-rCwVvcyXITzFfs1X-Mum5zodrGahfZ9NSDfaSzF7kbocoMmO0fi8m72nware9xs4bOiUrxe9LH6X4Q0qzoYo8TBY0e0He52L0ORo7BOewfCoVLW.D8GjFZ-DLUlizQZOXlbw-g/__results__.html#Types-Of-Features"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Categorical Variables.  \n",
    "So far we have only dealt with numeric variables however there are several non-numerical (**Categorical**) variables to be investigated as well.  \n",
    "Categorical variables are ones which provide information but are not quantified numerically. For instance, the `sub_area` variable gives us information about what neighbourhood the house is located in (ie. \"Kerrisdale\", \"Yaletown\" etc.). From our map plot, we found this information is important when considering house prices.  \n",
    "In order to use these categorical variables in our model, we encode them into a numerical representation called a [Dummy Variable]. We cover Dummy Variables in a later notebook.\n",
    "[Dummy Variable]: https://en.wikipedia.org/wiki/Dummy_variable_(statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's choose `property_type`, and `postal_code` to investigate.  \n",
    "We can use the `unique()` function on the categorical columns to see the different categories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# print(df['area'].unique())\n",
    "print(df['postal_code'].value_counts())\n",
    "print(df['property_type'].unique())\n",
    "# print(df['strata_type'].unique())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are some missing values, let's get rid of that data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "postal_codes = ['94501',\n",
    "'94608',\n",
    "'94607',\n",
    "'94005',\n",
    "'94014',]\n",
    "for postal_code in postal_codes:\n",
    "    df = df[df.postal_code != int(postal_code)]\n",
    "property_types = ['townhouse', 'foreclosure']\n",
    "for property_type in property_types:\n",
    "    df = df[df.property_type != property_type]\n",
    "print(df['postal_code'].value_counts())\n",
    "print(df['property_type'].value_counts())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualize these categories as box plots.  \n",
    "We use the `pandas.melt()` function to flatten our variables into a single column so we can plot.  \n",
    "The result of using `melt()` is most easily understood by displaying the result."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "vars_to_analyze = ['postal_code', 'property_type']\n",
    "df_melt = pd.melt(df, id_vars=['price'], value_vars=vars_to_analyze)\n",
    "for var in vars_to_analyze:\n",
    "    df_var = df_melt[df_melt['variable'] == var]\n",
    "    sns.boxplot(x=df_var['value'], y=df_var['price'])\n",
    "    x=plt.xticks(rotation=45)\n",
    "    plt.title(var)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Analysis of variance (ANOVA)\n",
    "We use ANOVA to explore how much variance occurs **between** groups (ie. *[price vs sub_area]* vs *[price vs area]* vs *[price vs property_type]* vs *[price vs strata_type]*) versus how much variance occurs **within** each group (ie *price vs sub_area* alone).  \n",
    "In the end this tells us is how useful it will be to group `price` into these 4 groups (and if including each variable in our model is useful to us).  \n",
    "Here's a quick YouTube video that may better explain ANOVA:  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo(id='ITf4vHhyGpc')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "def anova(df):\n",
    "    anv = pd.DataFrame()\n",
    "    anv['feature'] = vars_to_analyze\n",
    "    pvals = []\n",
    "#     import pdb; pdb.set_trace()\n",
    "    for c in vars_to_analyze:\n",
    "        samples = []\n",
    "        for cls in df[c].unique():\n",
    "            s = df[df[c] == cls]['price'].values\n",
    "            samples.append(s)\n",
    "        try:\n",
    "            print(samples)\n",
    "            pval = stats.f_oneway(*samples)[1]\n",
    "            print(pval)\n",
    "        except Exception as e:\n",
    "            pval=None\n",
    "            print(e)\n",
    "        finally:\n",
    "            pvals.append(pval)\n",
    "    anv['pval'] = pvals\n",
    "    return anv.sort_values('pval')\n",
    "\n",
    "a = anova(df)\n",
    "a['disparity'] = np.log(1./a['pval'].values)\n",
    "sns.barplot(data=a, x='feature', y='disparity')\n",
    "x=plt.xticks(rotation=45)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This gives us a rough estimate of effect each variable will have on our model. It makes intuitive sense that `sub_area` is highest since a home in Point Grey is likely to be more expensive than one in Grandview. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Hopefully the EDA has improved our intuition about the dataset. Now we can move onto data cleaning!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
