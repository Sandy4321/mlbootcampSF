{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Part 2 - Data Cleaning\n",
    "During our EDA we encountered some variables with incomplete or corrupted data.  \n",
    "In this notebook we will use Pandas to:\n",
    "* Remove outliers  \n",
    "* Handle missing, null or corrupted values  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import time\n",
    "from tqdm import tqdm\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from geopy import Nominatim\n",
    "import geojson\n",
    "import folium\n",
    "from branca.colormap import LinearColormap, StepColormap\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preview the data "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_dirty = pd.read_csv('./data/sf/data.csv')\n",
    "df_dirty.head(5) # display first 5 entries of DataFrame"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Remove outliers\n",
    "Recall from our EDA that our price data has outliers which result in high skewness and kurtosis values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# globally set our seaborn plot size to 12 by 8 inches:\n",
    "sns.set(rc={'figure.figsize':(12, 8)})\n",
    "\n",
    "def plot_prices(dataframe: pd.DataFrame, bins: list):\n",
    "    fig, ax = plt.subplots()\n",
    "    ax.set_xticks(bins)\n",
    "    plt.xticks(rotation='vertical')\n",
    "    return sns.distplot(dataframe.price, bins=bins)\n",
    "\n",
    "bins = range(int(df_dirty.price.min()),int(df_dirty.price.max()),500000)\n",
    "bins\n",
    "plot_prices(df_dirty.dropna(), bins)\n",
    "print(f'Skewness: {df_dirty.price.skew()}')\n",
    "print(f'Kurtosis: {df_dirty.price.kurt()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'max price before: {df_clean.price.max()}')\n",
    "cutoff = 8e6\n",
    "df_clean = df_dirty[df_dirty['price'] <= cutoff]\n",
    "print(f'max price after: {df_clean.price.max()}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bins = range(int(df_clean.price.min()),int(df_clean.price.max()),500000)\n",
    "plot_prices(df_clean, bins)\n",
    "print(\"Skewness: %f\" % df_clean['price'].skew())\n",
    "print(\"Kurtosis: %f\" % df_clean['price'].kurt())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The skewness and kurtosis values have improved. The distribution is still skewed however there are transformations we can apply to the dataset to make it more normally distributed. More on these transformations in a later notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_zero_sqft = (df_clean['sqft'] < 10).sum()\n",
    "print(\"There are {} entries with zero sqft\".format(num_zero_sqft))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean = df_clean[df_clean['sqft'] > 10]\n",
    "num_zero_sqft = (df_clean['sqft'] < 10).sum()\n",
    "print(\"There are {} entries with zero sqft\".format(num_zero_sqft))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There was also some `sqft` outliers at the very high range, let's rid ourselves of these values as well"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.regplot(df_clean['sqft'], df_clean['price'], fit_reg=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f'max sqft before: {df_clean.sqft.max()}')\n",
    "df_clean = df_clean[df_clean['sqft'] < 9000]\n",
    "print(f'max sqft after: {df_clean.sqft.max()}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Deal with Null and Missing values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "missing = df_clean.isnull().sum()\n",
    "missing = missing[missing > 0]\n",
    "missing.sort_values(inplace=True)\n",
    "missing.plot.bar()\n",
    "plt.title(\"Counts of Missing Values\")\n",
    "plt.show()\n",
    "missing_ratio = missing / len(df_clean)\n",
    "missing_ratio.plot.bar()\n",
    "plt.title(\"Ratio of Missing Values\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, we will choose to remove the `latlng` column completely. Although there may be some use cases for this data (eg. find distance to nearby schools, parks, etc.) we will remove it and keep the `postal_code` column as our location data.  \n",
    "We will also remove `real estate provider` since there are too many unique values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_clean.columns)\n",
    "df_clean = df_clean.drop(columns=['latlng', 'real estate provider'])\n",
    "print(df_clean.columns)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we could choose to drop all rows with null/missing values with `df.dropna()`, but we may benefit from \"imputing\" these values instead:  \n",
    "\n",
    "**Imputation** fills in the missing value with some number. The imputed value won't be exactly right in most cases, but it usually gives more accurate models than dropping the column entirely."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_dropna = df_clean.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import Imputer\n",
    "df_clean_imputed = df_clean.copy() # copy original for safe keeping\n",
    "columns_to_impute = ['bed', 'bath', 'sqft'] # only impute numerical columns\n",
    "imputer = Imputer(strategy='mean')\n",
    "imputed_columns = imputer.fit_transform(df_clean_imputed[columns_to_impute])\n",
    "df_clean_imputed[columns_to_impute] = imputed_columns\n",
    "df_clean_imputed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have imputed all of the values we can, let's drop the rest of the rows containing null values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_imputed = df_clean_imputed.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_imputed = df_clean_imputed[df_clean_imputed.postal_code != 94501] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_imputed.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " ## Save the dataframes to .csv"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_clean_dropna.to_csv('./data/sf/data_clean_dropna.csv', index=False)\n",
    "df_clean_imputed.to_csv('./data/sf/data_clean_imputed.csv', index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
